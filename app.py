import tempfile
import os
import streamlit as st
from langchain.memory import ConversationBufferMemory
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from loaders import *  
from dotenv import load_dotenv

load_dotenv()  # Carrega vari치veis do arquivo .env
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")


# Defini칞칚o dos tipos de arquivos v치lidos para upload
TIPOS_ARQUIVOS_VALIDOS = [
    'Site', 'Youtube', 'Pdf', 'Csv', 'Txt'
]

# Configura칞칚o dos modelos dispon칤veis para o provedor OpenAI
CONFIG_MODELOS = {
    'OpenAI': {
        'modelos': ['gpt-4o-mini', 'gpt-4o', 'o1-preview', 'o1-mini'],  # Modelos atualizados conforme solicitado
        'chat': ChatOpenAI
    }
}

# Inicializa칞칚o da mem칩ria de conversa
MEMORIA = ConversationBufferMemory()

def carrega_arquivos(tipo_arquivo, arquivo):
    """
    Carrega o conte칰do do arquivo ou URL fornecido pelo usu치rio.

    Args:
        tipo_arquivo (str): O tipo de arquivo a ser carregado.
        arquivo (str ou BytesIO): O arquivo ou URL fornecido pelo usu치rio.

    Returns:
        str: O conte칰do do documento carregado ou None em caso de erro.
    """
    try:
        if tipo_arquivo == 'Site':
            documento = carrega_site(arquivo)
        elif tipo_arquivo == 'Youtube':
            documento = carrega_youtube(arquivo)
        elif tipo_arquivo == 'Pdf':
            with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as temp:
                temp.write(arquivo.read())
                nome_temp = temp.name
            documento = carrega_pdf(nome_temp)
            os.remove(nome_temp)
        elif tipo_arquivo == 'Csv':
            with tempfile.NamedTemporaryFile(suffix='.csv', delete=False) as temp:
                temp.write(arquivo.read())
                nome_temp = temp.name
            documento = carrega_csv(nome_temp)
            os.remove(nome_temp)
        elif tipo_arquivo == 'Txt':
            with tempfile.NamedTemporaryFile(suffix='.txt', delete=False) as temp:
                temp.write(arquivo.read())
                nome_temp = temp.name
            documento = carrega_txt(nome_temp)
            os.remove(nome_temp)
        else:
            st.error('Tipo de arquivo inv치lido.')
            return None
        return documento
    except Exception as e:
        st.error(f"Erro ao carregar o arquivo: {e}")
        return None

def carrega_modelo(provedor, modelo, api_key, tipo_arquivo, arquivo):
    """
    Inicializa o modelo de linguagem com base no provedor e modelo selecionados.

    Args:
        provedor (str): O provedor de modelos (deve ser 'OpenAI').
        modelo (str): O modelo de linguagem selecionado.
        api_key (str): A chave API do OpenAI.
        tipo_arquivo (str): O tipo de arquivo fornecido pelo usu치rio.
        arquivo (str ou BytesIO): O arquivo ou URL fornecido pelo usu치rio.
    """
    # Valida칞칚o do provedor
    if provedor != 'OpenAI':
        st.error('Provedor inv치lido selecionado.')
        return

    # Valida칞칚o da chave API
    if not api_key:
        st.error('A chave API est치 vazia. Por favor, insira uma chave v치lida.')
        return

    # Log para depura칞칚o (exibindo apenas os primeiros caracteres da chave API por seguran칞a)
    st.write(f'**Provedor selecionado:** {provedor}')
    st.write(f'**Modelo selecionado:** {modelo}')
    st.write(f'**API Key fornecida:** {api_key[:4]}****')  # Exibindo apenas os primeiros 4 caracteres

    # Carregamento do documento
    documento = carrega_arquivos(tipo_arquivo, arquivo)
    if documento is None:
        st.error("Falha ao carregar o documento.")
        return

    # Defini칞칚o da mensagem do sistema para o modelo de linguagem
    system_message = f'''Voc칡 칠 um assistente amig치vel chamado Or치culo.
Voc칡 possui acesso 맙 seguintes informa칞칫es vindas 
de um documento {tipo_arquivo}: 

####
{documento}
####

Utilize as informa칞칫es fornecidas para basear as suas respostas.

Sempre que houver $ na sua sa칤da, substitua por S.

Se a informa칞칚o do documento for algo como "Just a moment...Enable JavaScript and cookies to continue" 
sugira ao usu치rio carregar novamente o Or치culo!'''

    # Log para depura칞칚o
    st.write('**System Message:**', system_message)

    # Cria칞칚o do template de prompt para o chat
    template = ChatPromptTemplate.from_messages([
        ('system', system_message),
        ('placeholder', '{chat_history}'),
        ('user', '{input}')
    ])

    try:
        # Inicializa칞칚o do cliente de chat do OpenAI com os modelos atualizados
        chat = CONFIG_MODELOS[provedor]['chat'](model=modelo, api_key=api_key)
    except Exception as e:
        st.error(f'Erro ao inicializar o modelo: {e}')
        return

    # Log para depura칞칚o
    st.write('**Cliente de chat inicializado com sucesso.**')

    # Cria칞칚o da cadeia de intera칞칚o entre o template e o modelo de chat
    chain = template | chat

    # Armazenamento da cadeia na sess칚o do Streamlit
    st.session_state['chain'] = chain
    st.success('Or치culo inicializado com sucesso!')

def pagina_chat():
    """
    Renderiza a p치gina principal de chat onde o usu치rio interage com o Or치culo.
    """
    st.header('游뱄 Bem-vindo ao Or치culo')

    # Recupera a cadeia de chat da sess칚o
    chain = st.session_state.get('chain')
    if chain is None:
        st.error('Carregue o Or치culo antes de iniciar o chat.')
        st.stop()

    # Recupera a mem칩ria de conversa da sess칚o ou inicializa uma nova
    memoria = st.session_state.get('memoria', MEMORIA)

    # Exibe o hist칩rico de mensagens na interface de chat
    for mensagem in memoria.buffer_as_messages:
        chat = st.chat_message(mensagem.type)
        chat.markdown(mensagem.content)

    # Input para o usu치rio enviar mensagens
    input_usuario = st.chat_input('Fale com o Or치culo')
    if input_usuario:
        # Exibe a mensagem do usu치rio
        chat = st.chat_message('human')
        chat.markdown(input_usuario)

        # Prepara para exibir a resposta do Or치culo
        chat = st.chat_message('ai')
        try:
            # Envia a entrada do usu치rio e o hist칩rico de chat para o modelo
            resposta = chat.write_stream(chain.stream({
                'input': input_usuario, 
                'chat_history': memoria.buffer_as_messages
            }))
        except Exception as e:
            st.error(f'Erro ao obter resposta do modelo: {e}')
            resposta = "Desculpe, ocorreu um erro ao processar sua solicita칞칚o."

        # Adiciona a mensagem do usu치rio e a resposta do Or치culo  mem칩ria de conversa
        memoria.chat_memory.add_user_message(input_usuario)
        memoria.chat_memory.add_ai_message(resposta)
        st.session_state['memoria'] = memoria

def sidebar():
    """
    Renderiza a barra lateral da aplica칞칚o com abas para upload de arquivos e configura칞칚o do modelo.
    """
    tabs = st.tabs(['Upload de Arquivos', 'Configura칞칚o do Modelo'])

    with tabs[0]:
        # Se칞칚o de upload de arquivos
        tipo_arquivo = st.selectbox('Selecione o tipo de arquivo', TIPOS_ARQUIVOS_VALIDOS)
        if tipo_arquivo == 'Site':
            arquivo = st.text_input('Digite a URL do site')
        elif tipo_arquivo == 'Youtube':
            arquivo = st.text_input('Digite a URL do v칤deo')
        elif tipo_arquivo == 'Pdf':
            arquivo = st.file_uploader('Fa칞a o upload do arquivo PDF', type=['pdf'])
        elif tipo_arquivo == 'Csv':
            arquivo = st.file_uploader('Fa칞a o upload do arquivo CSV', type=['csv'])
        elif tipo_arquivo == 'Txt':
            arquivo = st.file_uploader('Fa칞a o upload do arquivo TXT', type=['txt'])

    with tabs[1]:
        # Se칞칚o de configura칞칚o do modelo
        provedor = 'OpenAI'  # Provedor fixo
        st.write(f'**Provedor selecionado:** {provedor}')
        modelo = st.selectbox('Selecione o modelo', CONFIG_MODELOS[provedor]['modelos'])
        api_key = OPENAI_API_KEY  # Utiliza a chave API definida no c칩digo
        st.write(f'**API Key fornecida:** {api_key[:4]}****')  # Exibindo apenas os primeiros 4 caracteres

    # Bot칚o para inicializar o Or치culo
    if st.button('Inicializar Or치culo', use_container_width=True):
        # Valida칞칚o dos inputs com base no tipo de arquivo
        if tipo_arquivo in ['Site', 'Youtube'] and not arquivo:
            st.error('Por favor, forne칞a a URL.')
        elif tipo_arquivo in ['Pdf', 'Csv', 'Txt'] and not arquivo:
            st.error('Por favor, fa칞a o upload do arquivo.')
        elif not api_key:
            st.error('Por favor, insira a API key.')
        else:
            carrega_modelo(provedor, modelo, api_key, tipo_arquivo, arquivo)

    # Bot칚o para apagar o hist칩rico de conversa
    if st.button('Apagar Hist칩rico de Conversa', use_container_width=True):
        st.session_state['memoria'] = MEMORIA
        st.success('Hist칩rico de conversa apagado com sucesso!')

def main():
    """
    Fun칞칚o principal que organiza a estrutura da aplica칞칚o Streamlit.
    """
    with st.sidebar:
        sidebar()
    pagina_chat()

if __name__ == '__main__':
    main()
